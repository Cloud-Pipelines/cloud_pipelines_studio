"use strict";(self.webpackChunktangle_website=self.webpackChunktangle_website||[]).push([[1819],{5211:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/Caching_DisableCache-04d71d81d21c4ec47c30956b28dbdee7.png"},5690:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>c,default:()=>o,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"core-concepts/caching","title":"Understanding Caching in TangleML","description":"Learn how TangleML\'s sophisticated caching system saves time and resources","source":"@site/docs/core-concepts/caching.mdx","sourceDirName":"core-concepts","slug":"/core-concepts/caching","permalink":"/docs/core-concepts/caching","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Understanding Caching in TangleML","sidebar_label":"Caching","description":"Learn how TangleML\'s sophisticated caching system saves time and resources"},"sidebar":"docs","previous":{"title":"Inputs, Outputs and Data Flow","permalink":"/docs/core-concepts/understanding-inputs-outputs"},"next":{"title":"Lightweight Python Components","permalink":"/docs/component-development/creating-components"}}');var a=s(4848),t=s(8453);const r={title:"Understanding Caching in TangleML",sidebar_label:"Caching",description:"Learn how TangleML's sophisticated caching system saves time and resources"},c="Understanding Caching in TangleML",l={},d=[{value:"Why Caching Matters",id:"why-caching-matters",level:2},{value:"How Caching Works",id:"how-caching-works",level:2},{value:"The Cache Key",id:"the-cache-key",level:3},{value:"Content-Based vs. Lineage-Based Hashing",id:"content-based-vs-lineage-based-hashing",level:3},{value:"Reusing Running Executions",id:"reusing-running-executions",level:3},{value:"Cache Configuration",id:"cache-configuration",level:2},{value:"Controlling Cache Behavior",id:"controlling-cache-behavior",level:3},{value:"Cache Staleness Format",id:"cache-staleness-format",level:3},{value:"Data Retention and Purging",id:"data-retention-and-purging",level:2},{value:"Artifact Lifecycle",id:"artifact-lifecycle",level:3},{value:"What Survives Purging",id:"what-survives-purging",level:3},{value:"Cache Breaking Strategies",id:"cache-breaking-strategies",level:2},{value:"1. Date Parameters",id:"1-date-parameters",level:3},{value:"2. Cache Breaker Input",id:"2-cache-breaker-input",level:3},{value:"3. Disable Caching",id:"3-disable-caching",level:3},{value:"Summary",id:"summary",level:2}];function h(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"understanding-caching-in-tangleml",children:"Understanding Caching in TangleML"})}),"\n",(0,a.jsx)(n.p,{children:"TangleML's caching system is one of its most powerful features, designed to dramatically reduce compute time and accelerate your ML pipeline iterations. Unlike traditional pipeline systems, TangleML implements sophisticated caching strategies that can save hours or even days of computation time."}),"\n",(0,a.jsx)(n.h2,{id:"why-caching-matters",children:"Why Caching Matters"}),"\n",(0,a.jsx)(n.p,{children:"Imagine you have a pipeline that runs for two days, involving data preprocessing, model training, and evaluation. Without caching:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Every pipeline run would start from scratch"}),"\n",(0,a.jsx)(n.li,{children:"Small changes would require complete re-execution"}),"\n",(0,a.jsx)(n.li,{children:"Parallel experiments would duplicate work unnecessarily"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"With TangleML's caching:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Previous computations are automatically reused"}),"\n",(0,a.jsx)(n.li,{children:"Only changed components are re-executed"}),"\n",(0,a.jsx)(n.li,{children:"Multiple pipeline variants share common computations"}),"\n"]}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsx)(n.p,{children:"A pipeline that took a full day to run initially might complete in minutes on subsequent runs if most components can use cached results!"})}),"\n",(0,a.jsx)(n.h2,{id:"how-caching-works",children:"How Caching Works"}),"\n",(0,a.jsx)(n.h3,{id:"the-cache-key",children:"The Cache Key"}),"\n",(0,a.jsx)(n.p,{children:"TangleML generates a unique cache key for each task execution based on:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Container specification"})," - The exact container image, commands, and environment"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Input data hashes"})," - Cryptographic hashes of all input artifacts"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"When a task is about to execute, TangleML checks if an identical task has been run before by comparing cache keys."}),"\n",(0,a.jsx)(n.h3,{id:"content-based-vs-lineage-based-hashing",children:"Content-Based vs. Lineage-Based Hashing"}),"\n",(0,a.jsxs)(n.p,{children:["TangleML uses ",(0,a.jsx)(n.strong,{children:"content-based hashing"}),", which is superior to the lineage-based approach used by most other systems:"]}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Feature"}),(0,a.jsx)(n.th,{children:"Content-Based (TangleML)"}),(0,a.jsx)(n.th,{children:"Lineage-Based (Others)"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Component upgrades"})}),(0,a.jsx)(n.td,{children:"Downstream uses cache if outputs are identical"}),(0,a.jsx)(n.td,{children:"Must re-execute all downstream"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Non-deterministic components"})}),(0,a.jsx)(n.td,{children:"Downstream uses cache when output doesn't change"}),(0,a.jsx)(n.td,{children:"Always re-executes downstream"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Constant value replacement"})}),(0,a.jsx)(n.td,{children:"Can swap hardcoded values with components without breaking cache"}),(0,a.jsx)(n.td,{children:"Cache breaks when lineage changes"})]})]})]}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsx)(n.p,{children:"Content-based hashing means that if a component produces the same output (same hash), all downstream components can still use their cached results, even if the upstream component was re-executed!"})}),"\n",(0,a.jsx)(n.h3,{id:"reusing-running-executions",children:"Reusing Running Executions"}),"\n",(0,a.jsxs)(n.p,{children:["One of TangleML's unique features is the ability to reuse ",(0,a.jsx)(n.strong,{children:"still-running executions"}),". This is crucial for parallel pipeline submissions:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"Pipeline 1: [Data Processing] \u2192 [Training A] \u2192 [Evaluation]\nPipeline 2: [Data Processing] \u2192 [Training B] \u2192 [Evaluation]\nPipeline 3: [Data Processing] \u2192 [Training C] \u2192 [Evaluation]\n"})}),"\n",(0,a.jsx)(n.p,{children:"When submitted simultaneously:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Other systems"}),": Launch 3 separate data processing tasks"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"TangleML"}),": All pipelines share the same data processing execution"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"cache-configuration",children:"Cache Configuration"}),"\n",(0,a.jsx)(n.h3,{id:"controlling-cache-behavior",children:"Controlling Cache Behavior"}),"\n",(0,a.jsx)(n.p,{children:"You can control caching behavior at the component task level:"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Setting"}),(0,a.jsx)(n.th,{children:"Description"}),(0,a.jsx)(n.th,{children:"Example Use Case"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Default"})}),(0,a.jsx)(n.td,{children:"Cache enabled, no staleness limit"}),(0,a.jsx)(n.td,{children:"Most components"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Disabled"})}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:'max_cache_staleness: "P0D"'})}),(0,a.jsx)(n.td,{children:"Components reading volatile external data"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Time-limited"})}),(0,a.jsx)(n.td,{children:(0,a.jsx)(n.code,{children:'max_cache_staleness: "P7D"'})}),(0,a.jsx)(n.td,{children:"Data that becomes stale after a week"})]})]})]}),"\n",(0,a.jsx)(n.admonition,{type:"warning",children:(0,a.jsxs)(n.p,{children:["Components should be ",(0,a.jsx)(n.strong,{children:"pure functions"})," - given the same inputs, they should produce the same outputs. If your component reads from volatile sources, consider adding date parameters or disabling caching."]})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"...\nimplementation:\n  graph:\n    tasks:\n      ...\n      Fill all missing values using Pandas on CSV data:\n        executionOptions:\n          cachingStrategy:\n            maxCacheStaleness: P0D\n"})}),"\n",(0,a.jsx)(n.h3,{id:"cache-staleness-format",children:"Cache Staleness Format"}),"\n",(0,a.jsx)(n.p,{children:"Cache staleness uses RFC3339 duration format:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"P30D"})," - 30 days"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"P7D"})," - 7 days"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"PT1H"})," - 1 hour"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"P0D"})," - Disable caching"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"data-retention-and-purging",children:"Data Retention and Purging"}),"\n",(0,a.jsx)(n.h3,{id:"artifact-lifecycle",children:"Artifact Lifecycle"}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Stage"}),(0,a.jsx)(n.th,{children:"Duration"}),(0,a.jsx)(n.th,{children:"What Remains"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Active"})}),(0,a.jsx)(n.td,{children:"0-30 days"}),(0,a.jsx)(n.td,{children:"Full artifact data and metadata"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Purged"})}),(0,a.jsx)(n.td,{children:">30 days"}),(0,a.jsx)(n.td,{children:"Metadata only (size, hash, small values)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:(0,a.jsx)(n.strong,{children:"Deleted"})}),(0,a.jsx)(n.td,{children:"Never"}),(0,a.jsx)(n.td,{children:"Execution records persist indefinitely"})]})]})]}),"\n",(0,a.jsx)(n.admonition,{type:"warning",children:(0,a.jsx)(n.p,{children:"Artifacts are automatically purged after 30 days due to data retention policies. URLs to purged artifacts will return 404 errors, but metadata remains visible."})}),"\n",(0,a.jsx)(n.h3,{id:"what-survives-purging",children:"What Survives Purging"}),"\n",(0,a.jsx)(n.p,{children:"After purging, you can still see:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"File sizes"}),"\n",(0,a.jsx)(n.li,{children:"Content hashes"}),"\n",(0,a.jsx)(n.li,{children:"Directory structure"}),"\n",(0,a.jsx)(n.li,{children:"Small values (metrics, parameters)"}),"\n",(0,a.jsx)(n.li,{children:"Execution status and timing"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"cache-breaking-strategies",children:"Cache Breaking Strategies"}),"\n",(0,a.jsx)(n.p,{children:"When you need fresh data despite caching:"}),"\n",(0,a.jsx)(n.h3,{id:"1-date-parameters",children:"1. Date Parameters"}),"\n",(0,a.jsx)(n.p,{children:"For database queries, include cutoff dates:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"@component\ndef fetch_user_data(end_date: str) -> Dataset:\n    # Changing end_date naturally breaks cache\n    ...\n"})}),"\n",(0,a.jsx)(n.h3,{id:"2-cache-breaker-input",children:"2. Cache Breaker Input"}),"\n",(0,a.jsx)(n.p,{children:"For volatile sources without date control:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'@component\ndef search_web(query: str, cache_breaker: str = "") -> Results:\n    # Pass timestamp or random value to cache_breaker\n    ...\n'})}),"\n",(0,a.jsx)(n.h3,{id:"3-disable-caching",children:"3. Disable Caching"}),"\n",(0,a.jsx)(n.p,{children:"For components that should never cache:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'caching_strategy:\n  max_cache_staleness: "P0D" # Disables caching\n'})}),"\n",(0,a.jsx)("img",{src:s(5211).A,alt:"Disable Caching"}),"\n",(0,a.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(n.p,{children:"TangleML's caching system provides:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Automatic optimization"})," - No manual cache management needed"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Intelligent reuse"})," - Content-based hashing and running execution sharing"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Flexible control"})," - Configure staleness and breaking strategies"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Performance gains"})," - Dramatic reduction in execution time"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"By understanding and leveraging these caching capabilities, you can iterate faster, experiment more freely, and make the most of your computational resources."})]})}function o(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}}}]);